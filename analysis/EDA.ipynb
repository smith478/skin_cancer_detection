{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "The dataset we will use to train the model is the Skin Cancer MNIST: HAM10000 which can be found on Kaggle. There are also some great EDA notebooks that can be found under the kernels for this dataset. The EDA here is largely based on [this noteobok](https://www.kaggle.com/sid321axn/step-wise-approach-cnn-model-77-0344-accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major TODOs:\n",
    "- Create dockerfile and clean readme\n",
    "- Look at class activation maps and other localization techniques\n",
    "- Automate performance analysis tracking, create csv that stores metadata of what settings/hyperparameters were used\n",
    "- Setup hyperparameter tuning using keras tuner\n",
    "- Create a pipeline using TF Records, tf datasets, and tensorboard\n",
    "- Create ios mobile app\n",
    "- Allow various models to be trained\n",
    "- Try incorporating non image data (i.e. patient info) into a single end-to-end model\n",
    "- Split out this notebook and keep model training separate from EDA. Also have one for model performance analysis and localization/visualization (that take in trained model)\n",
    "- Add in class weighting (with description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a dictionary of images for our dataset and create a lookup table for readable names for our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join('..', 'data')\n",
    "\n",
    "# Merging images from both folders HAM10000_images_part1.zip and HAM10000_images_part2.zip into one dictionary\n",
    "\n",
    "image_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_dir, '*', '*.jpg'))}\n",
    "\n",
    "# This dictionary is useful for displaying more human-friendly labels later on\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(image_path_dict)} images in our dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will read and process the data. This will help later with creating labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df = pd.read_csv(os.path.join(base_dir, 'datasets_54339_104884_HAM10000_metadata.csv'))\n",
    "\n",
    "# Creating New Columns for better readability\n",
    "\n",
    "skin_df['path'] = skin_df['image_id'].map(image_path_dict.get)\n",
    "skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get) \n",
    "skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, check for null values. Test different methods of imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skin_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look at the distribution of our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(skin_df, height=300).mark_bar().encode(\n",
    "    x='count()',\n",
    "    y='cell_type',\n",
    "    color='cell_type',\n",
    "    tooltip='count()'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various methods by which the ground truth labels were established with this dataset:\n",
    "\n",
    "1. Histopathology(Histo): Histopathologic diagnoses of excised lesions have been performed by specialized dermatopathologists.\n",
    "2. Confocal: Reflectance confocal microscopy is an in-vivo imaging technique with a resolution at near-cellular level , and some facial benign with a grey-world assumption of all training-set images in Lab-color space before and after manual histogram changes.\n",
    "3. Follow-up: If nevi monitored by digital dermatoscopy did not show any changes during 3 follow-up visits or 1.5 years biologists accepted this as evidence of biologic benignity. Only nevi, but no other benign diagnoses were labeled with this type of ground-truth because dermatologists usually do not monitor dermatofibromas, seborrheic keratoses, or vascular lesions.\n",
    "4. Consensus: For typical benign cases without histopathology or followup biologists provide an expert-consensus rating of authors PT and HK. They applied the consensus label only if both authors independently gave the same unequivocal benign diagnosis. Lesions with this type of groundtruth were usually photographed for educational reasons and did not need further follow-up or biopsy for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(skin_df, height=300).mark_bar().encode(\n",
    "    x='count()',\n",
    "    y='dx_type',\n",
    "    color='dx_type',\n",
    "    tooltip='count()'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of localization field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(skin_df, height=400).mark_bar().encode(\n",
    "    x='count()',\n",
    "    y='localization',\n",
    "    color='localization',\n",
    "    tooltip='count()'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of patient age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(skin_df[-skin_df['age'].isnull()]).mark_bar().encode(\n",
    "    alt.X(\"age:Q\", bin=True),\n",
    "    y='count()',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at sex distribution in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(skin_df, height=400).mark_bar().encode(\n",
    "    x='count()',\n",
    "    y='sex',\n",
    "    color='sex',\n",
    "    tooltip='count()'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at cell type (the target) by median age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(skin_df[-skin_df['age'].isnull()], height=400).mark_bar().encode(\n",
    "    x='median(age)',\n",
    "    y='cell_type',\n",
    "    color='cell_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality\n",
    "\n",
    "Look for duplicate images from patients and make sure datasets are stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = skin_df.groupby('lesion_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='image_id', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original dataset had {skin_df.shape[0]} records, there are {df.shape[0]} unique lesions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train, Test, and Val Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO Set aside a test set to evaluate model after it has been trained\n",
    "- TODO Use TF Records and tf dataset to store training dataset as an alternative to data generator below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are numerous images taken for some patients, therefore we will choose a single image from each patient. Then we will take a stratified sample across our target variable in order to create our train test and validation directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a dataframe containing a single image from each patient. Note that we could also try including these duplicates, just making sure that when we split our dataset we keep patients in a single train, test, or val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed (random_state) for reproducibility and deterministic train/val/test sets\n",
    "df_dataset = skin_df.sample(frac=1, random_state=123).drop_duplicates(subset='lesion_id').copy()\n",
    "df_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = [\n",
    "    'nv' ,\n",
    "    'mel', \n",
    "    'bkl', \n",
    "    'bcc',\n",
    "    'akiec',\n",
    "    'vasc',\n",
    "    'df',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use image generator to build model, then below use the newer tf records to orchastrate training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "\n",
    "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, df_dataset.sort_values(['cell_type']).groupby('cell_type')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
    "        c_ax.imshow(np.asarray(Image.open(c_row['path'])))\n",
    "        c_ax.axis('off')\n",
    "# The line below will save the images to disk\n",
    "#fig.savefig('category_samples.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = np.asarray(Image.open(df_dataset['path'][0])).shape\n",
    "print('Image shape:', img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(df_dataset['path'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = tf.image.random_brightness(img, max_delta=0.2)\n",
    "# augmented = tf.image.random_flip_up_down(img)\n",
    "# augmented = tf.image.random_flip_left_right(img)\n",
    "# augmented = tf.image.random_saturation(image=img, lower=0.7, upper=1.3)\n",
    "# augmented = tf.image.random_hue(image=img, max_delta=0.03)\n",
    "# augmented = tf.image.random_contrast(image=img, lower=0.7, upper=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(augmented)\n",
    "ax.axis('off')\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create stratified train/test/val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset['path']\n",
    "y = df_dataset['cell_type_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a seed (random_state) for reproducibility and deterministic train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.111, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({\n",
    "    'path': X_train,\n",
    "    'cell_type_idx': y_train\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(path):\n",
    "    return np.asarray(Image.open(path), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_file(X_path, y):\n",
    "    \"\"\"\n",
    "    X_path: (pandas series) contains the file paths to the images\n",
    "    y: (pandas series of type int) the target label\n",
    "    \n",
    "    return a pair of numpy arrays representing (features, target)\n",
    "    \"\"\"\n",
    "    \n",
    "    X = X_path.apply(convert_image_to_array)\n",
    "    X /= 255.\n",
    "    X = X.values\n",
    "    X = list(X)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    y = y.map(lambda y: to_categorical(y, num_classes=len(CLASS_LABELS)))\n",
    "    y = y.values\n",
    "    y = list(y)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(path, model):\n",
    "    x = convert_image_to_array(path=path)\n",
    "    x /= 255.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = create_model_file(X_path=X_val, y=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data generator for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size, image_size=(450, 600), dtype=np.float32):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, image_size[0], image_size[1], 3), dtype=dtype)\n",
    "    batch_labels = np.zeros((batch_size, len(CLASS_LABELS)), dtype=dtype)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Initialize a counter\n",
    "    i = 0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        # Get the next batch \n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_path = data.iloc[idx]['path']\n",
    "            label = data.iloc[idx]['cell_type_idx']\n",
    "            \n",
    "            # one hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=len(CLASS_LABELS))\n",
    "            # read the image\n",
    "            img = np.asarray(Image.open(img_path), dtype=dtype)\n",
    "            \n",
    "            # add image augmentation\n",
    "            if np.random.uniform() < 0.15:\n",
    "                img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "            if np.random.uniform() < 0.15:\n",
    "                img = tf.image.random_flip_up_down(img)\n",
    "            if np.random.uniform() < 0.15:\n",
    "                img = tf.image.random_flip_left_right(img)\n",
    "            if np.random.uniform() < 0.15:\n",
    "                img = tf.image.random_saturation(image=img, lower=0.7, upper=1.3)\n",
    "            if np.random.uniform() < 0.15:\n",
    "                img = tf.image.random_hue(image=img, max_delta=0.03)\n",
    "            if np.random.uniform() < 0.15:\n",
    "                img = tf.image.random_contrast(image=img, lower=0.7, upper=1.3)\n",
    "                \n",
    "            \n",
    "            # normalize the image pixels\n",
    "            img = img/255.\n",
    "\n",
    "            batch_data[count] = img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "            count+=1\n",
    "\n",
    "            if count==batch_size:\n",
    "                break\n",
    "            \n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "            \n",
    "        if i>=steps:\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Utility Functions\n",
    "\n",
    "Define some functions that will help simplify the fine-tuning pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, freeze_layer_name):\n",
    "    for layer in model.layers:\n",
    "        if layer.name != freeze_layer_name:\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            break\n",
    "            \n",
    "def unfreeze_batch_norm(model):\n",
    "    for layer in model.layers:\n",
    "        if layer.__class__.__name__ == 'BatchNormalization':\n",
    "            layer.trainable = True\n",
    "\n",
    "def print_layer_trainable(model):\n",
    "    for layer in model.layers:\n",
    "        print('{0}:\\t{1}'.format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "TODO Add in MobileNetV2, EfficientNet, DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "input_tensor = layers.Input(shape=(450, 600, 3), name='ImageInput')\n",
    "\n",
    "model = Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine where to freeze and cut off base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_layer_name = 'block14_sepconv1_act'\n",
    "freeze_layer_name = 'add_10'\n",
    "\n",
    "transfer_layer = model.get_layer(transfer_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = tf.keras.Model(inputs=model.input, outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layers(conv_model, freeze_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model, num_classes, pooling='avg', final_conv_layer='vgg_separable'):\n",
    "    # Get the output of the base model on which we will build\n",
    "    x = base_model.layers[-1].output\n",
    "    \n",
    "    if final_conv_layer == 'xception':\n",
    "        x = layers.SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n",
    "        x = layers.BatchNormalization(name='block14_sepconv2_bn')(x)\n",
    "        x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n",
    "    elif final_conv_layer == 'non_separable':\n",
    "        x = layers.Conv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_conv2')(x)\n",
    "        x = layers.BatchNormalization(name='block14_conv2_bn')(x)\n",
    "        x = layers.Activation('relu', name='block14_conv2_act')(x)\n",
    "    elif final_conv_layer == 'vgg_separable':\n",
    "        x = layers.SeparableConv2D(2048, (3,3), activation='relu', padding='same', name='block14_sepconv2')(x)\n",
    "    elif final_conv_layer == 'vgg':\n",
    "        x = layers.Conv2D(2048, (3,3), activation='relu', padding='same', name='block14_sepconv2')(x)\n",
    "    else:\n",
    "        raise ValueError('`final_conv_layer` should be one of the following: xception, non_separable, vgg_separable, or vgg')\n",
    "    \n",
    "    if pooling == 'global_avg':\n",
    "        x = layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    elif pooling == 'global_max':\n",
    "        x = layers.GlobalMaxPooling2D(name='global_max_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = layers.MaxPooling2D((2,2), name='local_max_pool')(x)\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "    elif pooling == 'avg':\n",
    "        x = layers.AveragePooling2D((2,2), name='local_avg_pool')(x)\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "    else:\n",
    "        raise ValueError('`pooling` should be one of the following: global_avg, global_max, max')\n",
    "        \n",
    "    x = layers.Dense(num_classes, activation='softmax', name='prediction')(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = tf.keras.Model(base_model.input, x, name='Xception')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(base_model=conv_model, num_classes=len(CLASS_LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_batch_norm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer_trainable(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 8\n",
    "model_path='../serialized_models/model_X{epoch:02d}-{val_loss:.4f}.h5'\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=model_path, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    x=data_gen(data=train_data, batch_size=batch_size), epochs=epochs, callbacks=callbacks, validation_data=val_data, steps_per_epoch=int(NUM_TRAIN/batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 9\n",
    "\n",
    "X_test_example = X_test[test_num]\n",
    "y_test_example = y_test[test_num]\n",
    "\n",
    "y_hat = model_predict(path=X_test_example, model=model)\n",
    "\n",
    "print(f'Ground truth label: {y_test_example} \\n Predicted label: {np.argmax(y_hat)} \\t Probability: {np.max(y_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_model_file(X_path=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=test_data[0], y=test_data[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
